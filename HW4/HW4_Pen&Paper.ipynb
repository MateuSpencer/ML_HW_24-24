{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "X0\n",
      "\n",
      "Bernoulli Likelihood (Cluster 1): 0.3\n",
      "Bernoulli Likelihood (Cluster 2): 0.7\n",
      "Gaussian Likelihood (Cluster 1): 0.06657529920303393\n",
      "Gaussian Likelihood (Cluster 2): 0.11961837142058572\n",
      "likelihood (Cluster 1): 0.019972589760910178\n",
      "likelihood (Cluster 2): 0.08373285999441\n",
      "Denominator): 0.05185272487766009\n",
      "\n",
      "\n",
      "X1\n",
      "\n",
      "Bernoulli Likelihood (Cluster 1): 0.7\n",
      "Bernoulli Likelihood (Cluster 2): 0.30000000000000004\n",
      "Gaussian Likelihood (Cluster 1): 0.05004888824270901\n",
      "Gaussian Likelihood (Cluster 2): 0.0681905803254947\n",
      "likelihood (Cluster 1): 0.035034221769896304\n",
      "likelihood (Cluster 2): 0.020457174097648412\n",
      "Denominator): 0.027745697933772358\n",
      "\n",
      "\n",
      "X2\n",
      "\n",
      "Bernoulli Likelihood (Cluster 1): 0.7\n",
      "Bernoulli Likelihood (Cluster 2): 0.30000000000000004\n",
      "Gaussian Likelihood (Cluster 1): 0.06837452355368487\n",
      "Gaussian Likelihood (Cluster 2): 0.12958103481626038\n",
      "likelihood (Cluster 1): 0.047862166487579405\n",
      "likelihood (Cluster 2): 0.038874310444878116\n",
      "Denominator): 0.04336823846622876\n",
      "\n",
      "\n",
      "X3\n",
      "\n",
      "Bernoulli Likelihood (Cluster 1): 0.3\n",
      "Bernoulli Likelihood (Cluster 2): 0.7\n",
      "Gaussian Likelihood (Cluster 1): 0.059046993443730274\n",
      "Gaussian Likelihood (Cluster 2): 0.12450008976589248\n",
      "likelihood (Cluster 1): 0.01771409803311908\n",
      "likelihood (Cluster 2): 0.08715006283612474\n",
      "Denominator): 0.052432080434621914\n",
      "Posterior Probabilities:\n",
      " [[0.19258959 0.80741041]\n",
      " [0.63134512 0.36865488]\n",
      " [0.55181128 0.44818872]\n",
      " [0.16892423 0.83107577]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import bernoulli, multivariate_normal\n",
    "\n",
    "# Given data points\n",
    "data = np.array([\n",
    "    [1, 0.6, 0.1],\n",
    "    [0, -0.4, 0.8],\n",
    "    [0, 0.2, 0.5],\n",
    "    [1, 0.4, -0.1]\n",
    "])\n",
    "\n",
    "# Given parameters\n",
    "pi = np.array([0.5, 0.5])\n",
    "p = np.array([0.3, 0.7])\n",
    "N1 = {\n",
    "    'mean': np.array([1, 1]),\n",
    "    'cov': np.array([[2, 0.5], [0.5, 2]])\n",
    "}\n",
    "N2 = {\n",
    "    'mean': np.array([0, 0]),\n",
    "    'cov': np.array([[1.5, 1], [1, 1.5]])\n",
    "}\n",
    "\n",
    "# Initialize arrays to store posterior probabilities\n",
    "posterior_probs = np.zeros((len(data), 2))\n",
    "\n",
    "# E-step: Compute posterior probabilities\n",
    "for i in range(len(data)):\n",
    "    print(f\"\\n\\nX{ i }\\n\")\n",
    "    likelihood_bernoulli_1 = p[0]**data[i, 0] * (1-p[0])**(1-data[i, 0])\n",
    "    likelihood_bernoulli_2 = p[1]**data[i, 0] * (1-p[1])**(1-data[i, 0])\n",
    "    print(f\"Bernoulli Likelihood (Cluster 1): {likelihood_bernoulli_1}\")\n",
    "    print(f\"Bernoulli Likelihood (Cluster 2): {likelihood_bernoulli_2}\")\n",
    "    \n",
    "    likelihood_gaussian_1 = multivariate_normal.pdf(data[i, 1:], mean=N1['mean'], cov=N1['cov'])\n",
    "    likelihood_gaussian_2 = multivariate_normal.pdf(data[i, 1:], mean=N2['mean'], cov=N2['cov'])\n",
    "    print(f\"Gaussian Likelihood (Cluster 1): {likelihood_gaussian_1}\")\n",
    "    print(f\"Gaussian Likelihood (Cluster 2): {likelihood_gaussian_2}\")\n",
    "    \n",
    "    likelihood_1 = likelihood_bernoulli_1 * likelihood_gaussian_1\n",
    "    likelihood_2 = likelihood_bernoulli_2 * likelihood_gaussian_2\n",
    "    print(f\"likelihood (Cluster 1): {likelihood_1}\")\n",
    "    print(f\"likelihood (Cluster 2): {likelihood_2}\")\n",
    "    \n",
    "    denominator = pi[0] * likelihood_1 + pi[1] * likelihood_2\n",
    "    print(f\"Denominator): {denominator}\")\n",
    "    \n",
    "    posterior_probs[i, 0] = (pi[0] * likelihood_bernoulli_1 * likelihood_gaussian_1) / denominator\n",
    "    posterior_probs[i, 1] = (pi[1] * likelihood_bernoulli_2 * likelihood_gaussian_2) / denominator\n",
    "\n",
    "print(\"Posterior Probabilities:\\n\", posterior_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PI: [0.38616755 0.61383245]\n",
      "\n",
      "\n",
      "\n",
      "PRIORS\n",
      "\n",
      "cluster: 0\n",
      "p_sum: 0.36151382107026986\n",
      "denominator: 1.5446702187154808\n",
      "cluster: 1\n",
      "p_sum: 1.63848617892973\n",
      "denominator: 2.455329781284519\n",
      "p: [0.23403948 0.66731817]\n",
      "\n",
      "\n",
      "\n",
      "N1 mean: [0.026509   0.50712978]\n",
      "N1 cov:\n",
      " [[1.08904974 0.37439926]\n",
      " [0.37439926 0.33897366]]\n",
      "\n",
      "\n",
      "N2 mean: [0.30914476 0.2104205 ]\n",
      "N2 cov:\n",
      " [[ 0.20386353 -0.02360135]\n",
      " [-0.02360135  0.14840009]]\n"
     ]
    }
   ],
   "source": [
    "# M-step: Update model parameters\n",
    "new_pi = np.mean(posterior_probs, axis=0)\n",
    "print(\"PI:\", new_pi)\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "# Update p\n",
    "print(\"PRIORS\\n\")\n",
    "new_p = np.zeros(2)\n",
    "for j in range(2): # 2 clusters\n",
    "    print(\"cluster:\", j)\n",
    "    p_sum = 0\n",
    "    for i in range(len(data)):\n",
    "        p_sum += data[i, 0] * posterior_probs[i, j]\n",
    "    print(\"p_sum:\", p_sum)\n",
    "    denominator = np.sum(posterior_probs[:, j])\n",
    "    print(\"denominator:\", denominator)\n",
    "    new_p[j] = p_sum / denominator\n",
    "print(\"p:\", new_p)\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "# Update N1 and N2\n",
    "new_N1_mean = np.zeros(2)\n",
    "new_N2_mean = np.zeros(2)\n",
    "new_N1_cov = np.zeros((2, 2))\n",
    "new_N2_cov = np.zeros((2, 2))\n",
    "\n",
    "for j in range(2): # 2 clusters\n",
    "    mean_sum = np.zeros(2)\n",
    "    cov_sum = np.zeros((2, 2))\n",
    "    for i in range(len(data)):\n",
    "        mean_sum += posterior_probs[i, j] * data[i, 1:]\n",
    "        cov_sum += posterior_probs[i, j] * np.outer(data[i, 1:] - [N1['mean'], N2['mean']][j], data[i, 1:] - [N1['mean'], N2['mean']][j])\n",
    "    if j == 0:\n",
    "        new_N1_mean = mean_sum / np.sum(posterior_probs[:, j])\n",
    "        new_N1_cov = cov_sum / np.sum(posterior_probs[:, j])\n",
    "    else:\n",
    "        new_N2_mean = mean_sum / np.sum(posterior_probs[:, j])\n",
    "        new_N2_cov = cov_sum / np.sum(posterior_probs[:, j])\n",
    "\n",
    "\n",
    "# Update the model parameters\n",
    "pi = new_pi\n",
    "p = new_p\n",
    "\n",
    "N1['mean'] = new_N1_mean\n",
    "N2['mean'] = new_N2_mean\n",
    "N1['cov'] = new_N1_cov\n",
    "N2['cov'] = new_N2_cov\n",
    "\n",
    "\n",
    "print(\"N1 mean:\", N1['mean'])\n",
    "print(\"N1 cov:\\n\", N1['cov'])\n",
    "print(\"\\n\")\n",
    "print(\"N2 mean:\", N2['mean'])\n",
    "print(\"N2 cov:\\n\", N2['cov'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Posterior for Cluster 1: 0.20697271237150058\n",
      "Posterior for Cluster 2: 0.7930272876284995\n"
     ]
    }
   ],
   "source": [
    "# Given model parameters\n",
    "π1 = 0.5\n",
    "π2 = 0.5\n",
    "p1 = 0.3\n",
    "p2 = 0.7\n",
    "μ1 = np.array([1, 1])\n",
    "Σ1 = np.array([[2, 0.5], [0.5, 2]])\n",
    "μ2 = np.array([0, 0])\n",
    "Σ2 = np.array([[1.5, 1], [1, 1.5]])\n",
    "\n",
    "# New observation\n",
    "x_new = np.array([1, 0.3, 0.7])\n",
    "\n",
    "# Calculate the likelihoods for the new observation\n",
    "likelihood_cluster1 = (\n",
    "    bernoulli.pmf(1, p1) *\n",
    "    multivariate_normal.pdf(x_new[1:], mean=μ1, cov=Σ1)\n",
    ")\n",
    "\n",
    "likelihood_cluster2 = (\n",
    "    bernoulli.pmf(1, p2) *\n",
    "    multivariate_normal.pdf(x_new[1:], mean=μ2, cov=Σ2)\n",
    ")\n",
    "\n",
    "# Calculate unnormalized posteriors\n",
    "unnormalized_posterior1 = π1 * likelihood_cluster1\n",
    "unnormalized_posterior2 = π2 * likelihood_cluster2\n",
    "\n",
    "# Normalize the posteriors\n",
    "posterior1 = unnormalized_posterior1 / (unnormalized_posterior1 + unnormalized_posterior2)\n",
    "posterior2 = unnormalized_posterior2 / (unnormalized_posterior1 + unnormalized_posterior2)\n",
    "\n",
    "print(\"Posterior for Cluster 1:\", posterior1)\n",
    "print(\"Posterior for Cluster 2:\", posterior2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.00998629 0.04186643]\n",
      " [0.01751711 0.01022859]\n",
      " [0.02393108 0.01943716]\n",
      " [0.00885705 0.04357503]]\n",
      "[1 0 0 1]\n",
      "[[0.  2.7 1.8 0.4]\n",
      " [2.7 0.  0.9 2.7]\n",
      " [1.8 0.9 0.  1.8]\n",
      " [0.4 2.7 1.8 0. ]]\n",
      "[0.2  0.45 0.45 0.2 ]\n",
      "Silhouette score of the first cluster under Manhattan distance: 0.7916666666666665\n",
      "Silhouette score of the second cluster under Manhattan distance: 0.911111111111111\n"
     ]
    }
   ],
   "source": [
    "# Given observations\n",
    "observations = np.array([\n",
    "    [1, 0.6, 0.1],\n",
    "    [0, -0.4, 0.8],\n",
    "    [0, 0.2, 0.5],\n",
    "    [1, 0.4, -0.1]\n",
    "])\n",
    "\n",
    "# Given parameters\n",
    "pi = np.array([0.5, 0.5])\n",
    "p = np.array([0.3, 0.7])\n",
    "mean = np.array([[1, 1], [0, 0]])\n",
    "cov = np.array([[[2, 0.5], [0.5, 2]], [[1.5, 1], [1, 1.5]]])\n",
    "\n",
    "# Step 1: Calculate the likelihood of each observation belonging to each cluster\n",
    "likelihoods = np.zeros((len(observations), len(pi)))\n",
    "for i in range(len(observations)):\n",
    "    for j in range(len(pi)):\n",
    "        likelihoods[i, j] = pi[j] * p[j] ** observations[i, 0] * (1 - p[j]) ** (1 - observations[i, 0]) * \\\n",
    "                            multivariate_normal.pdf(observations[i, 1:], mean[j], cov[j])\n",
    "        \n",
    "print(likelihoods)\n",
    "\n",
    "# Step 2: Assign each observation to the cluster with the highest likelihood\n",
    "assignments = np.argmax(likelihoods, axis=1)\n",
    "\n",
    "print(assignments)\n",
    "\n",
    "# Now, we have assigned each observation to a cluster (0 or 1).\n",
    "\n",
    "# Step 3: Calculate the Manhattan distance between each observation and all other observations\n",
    "manhattan_distances = np.zeros((len(observations), len(observations)))\n",
    "for i in range(len(observations)):\n",
    "    for j in range(len(observations)):\n",
    "        manhattan_distances[i, j] = np.abs(observations[i] - observations[j]).sum()\n",
    "\n",
    "print(manhattan_distances)\n",
    "\n",
    "\n",
    "# Step 4: Calculate the average distance of each observation to all other observations in the same cluster\n",
    "average_distances_same_cluster = np.zeros(len(observations))\n",
    "for i in range(len(observations)):\n",
    "    same_cluster_indices = np.where(assignments == assignments[i])[0]\n",
    "    same_cluster_distances = manhattan_distances[i, same_cluster_indices]\n",
    "    average_distances_same_cluster[i] = np.mean(same_cluster_distances)\n",
    "\n",
    "print(average_distances_same_cluster)\n",
    "\n",
    "\n",
    "# Step 5: Calculate the average distance of each observation to all observations in the other cluster\n",
    "average_distances_other_cluster = np.zeros(len(observations))\n",
    "for i in range(len(observations)):\n",
    "    other_cluster_indices = np.where(assignments != assignments[i])[0]\n",
    "    other_cluster_distances = manhattan_distances[i, other_cluster_indices]\n",
    "    average_distances_other_cluster[i] = np.mean(other_cluster_distances)\n",
    "\n",
    "# Step 6: Calculate the silhouette score for each observation\n",
    "silhouette_scores = (average_distances_other_cluster - average_distances_same_cluster) / \\\n",
    "                    np.maximum(average_distances_other_cluster, average_distances_same_cluster)\n",
    "\n",
    "# Step 7: Calculate the average silhouette score for both clusters\n",
    "silhouette_cluster_0 = np.mean(silhouette_scores[assignments == 0])\n",
    "silhouette_cluster_1 = np.mean(silhouette_scores[assignments == 1])\n",
    "\n",
    "print(\"Silhouette score of the first cluster under Manhattan distance:\", silhouette_cluster_0)\n",
    "print(\"Silhouette score of the second cluster under Manhattan distance:\", silhouette_cluster_1)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
