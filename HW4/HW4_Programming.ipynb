{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import arff\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import datasets, metrics, cluster, mixture\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.cluster import KMeans\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning) # Ignore FutureWarnings\n",
    "\n",
    "\n",
    "data = arff.loadarff('column_diagnosis.arff')\n",
    "df = pd.DataFrame(data[0])\n",
    "\n",
    "# Features\n",
    "X = df.drop(columns='class').values\n",
    "\n",
    "# Normalization\n",
    "scaler = MinMaxScaler()\n",
    "X_normalized = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K = 2, Silhouette Score: 0.36044124340441114\n",
      "K = 3, Silhouette Score: 0.29579055730002257\n",
      "K = 4, Silhouette Score: 0.27442402122340176\n",
      "K = 5, Silhouette Score: 0.23823928397844843\n",
      "K = 2, Purity Score: 0.632258064516129\n",
      "K = 3, Purity Score: 0.667741935483871\n",
      "K = 4, Purity Score: 0.6612903225806451\n",
      "K = 5, Purity Score: 0.6774193548387096\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def purity_score(y_true, y_pred):\n",
    "    confusion_matrix = metrics.cluster.contingency_matrix(y_true, y_pred)\n",
    "    return np.sum(np.amax(confusion_matrix, axis=0)) / np.sum(confusion_matrix) \n",
    "\n",
    "\n",
    "k_values = [2, 3, 4, 5]\n",
    "\n",
    "silhouette_scores = {}\n",
    "purity_scores = {}\n",
    "\n",
    "for k in k_values:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=0)\n",
    "    cluster_labels = kmeans.fit_predict(X_normalized)\n",
    "\n",
    "    silhouette = metrics.silhouette_score(X_normalized, cluster_labels)\n",
    "    silhouette_scores[k] = silhouette\n",
    "    \n",
    "    purity = purity_score(df['class'], cluster_labels)\n",
    "    purity_scores[k] = purity\n",
    "\n",
    "for k, silhouette in silhouette_scores.items():\n",
    "    print(f\"K = {k}, Silhouette Score: {silhouette}\")\n",
    "for k, purity in purity_scores.items():\n",
    "    print(f\"K = {k}, Purity Score: {purity}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
